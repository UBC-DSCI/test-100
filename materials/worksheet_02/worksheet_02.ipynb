{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Worksheet 2: Introduction to Reading Data\n",
    "\n",
    "You can read more about [course policies](https://github.com/UBC-DSCI/dsci-100/blob/master/policies.md) on the [course website](https://github.com/UBC-DSCI/dsci-100).\n",
    "\n",
    "### Lecture and Tutorial Learning Goals:\n",
    "\n",
    "After completing this week's lecture and tutorial work, you will be able to:\n",
    "\n",
    "* read data using an absolute path\n",
    "* read data using a relative path \n",
    "* read data from the internet using a URL \n",
    "* understand the difference between:\n",
    "    - `read_csv` \n",
    "    - `read_tsv`\n",
    "    - `read_csv2`\n",
    "    - `read_delim`\n",
    "* match the following tidyverse read_* function arguments to their descriptions:\n",
    "    - `file` \n",
    "    - `delim`\n",
    "    - `col_names`\n",
    "    - `skip`\n",
    "* choose the appropriate tidyverse read_* function and function arguments to load a given tabular data set into R.\n",
    "* identify metadata in a file and read the fle using the argument `skip`\n",
    "* use the rvest `html_nodes` and `html_text` functions to scrape data from a .html file on the web\n",
    "* compare downloading tabular data from a plain text file (e.g. *.csv) from the web versus scraping data from a .html file\n",
    "\n",
    "This worksheet covers parts of [Chapter 2](https://ubc-dsci.github.io/introduction-to-datascience/reading.html) of the online textbook. You should read this chapter before attempting the worksheet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Run this cell before continuing. \n",
    "library(tidyverse)\n",
    "library(testthat)\n",
    "library(digest)\n",
    "library(repr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Comparing Absolute Paths, Relative Paths, and URLs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ee65583a25cd7a7aa92d0c4aca53be97",
     "grade": false,
     "grade_id": "cell-33341d6ba389a6a5",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "**Question 1.1** Multiple Choice:\n",
    "\n",
    "If you needed to read a file using an absolute path, what would be the first symbol in your argument (...) when using the `read_csv` function?\n",
    "\n",
    "A. `read_csv(\">...\")`\n",
    "\n",
    "B. `read_csv(\";...\")`\n",
    "\n",
    "C. `read_csv(\"...\")`\n",
    "\n",
    "D. `read_csv(\"/...\")`\n",
    "\n",
    "*Assign your answer to an object called `answer1`.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3c2bfc680862dd8093576cdcf28cd165",
     "grade": false,
     "grade_id": "cell-6bdc2f57a189abcf",
     "locked": false,
     "schema_version": 2,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# Assign your answer to an object called: answer1\n",
    "# Make sure the correct answer is an uppercase letter. \n",
    "# Surround your answer with quotation marks.\n",
    "# Replace the fail() with your answer. \n",
    "\n",
    "# your code here\n",
    "fail() # No Answer - remove if you provide an answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "cb1e48fa6bcf009c4367fd0555f8a918",
     "grade": true,
     "grade_id": "cell-62f0d28a4d321e00",
     "locked": true,
     "points": 1,
     "schema_version": 2,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "test_that('Solution is incorrect', {\n",
    "    expect_that(exists('answer1'), is_true())\n",
    "    expect_equal(digest(answer1), 'c1f86f7430df7ddb256980ea6a3b57a4') # we hid the answer to the test here so you can't see it, but we can still run the test\n",
    "    \n",
    "})\n",
    "print(\"Success!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f318f555d8708edb181ebd4b8b6b75da",
     "grade": false,
     "grade_id": "cell-b91542cf20075a6d",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "**Question 1.2** True or False: \n",
    "\n",
    "The file argument in the `read_csv` function that uses an absolute path can *never* look like that of a relative path?\n",
    "\n",
    "*Assign your answer to an object called `answer2`.* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9f734f61c68f3c21ab6b191b311b394f",
     "grade": false,
     "grade_id": "cell-419826637ad2ec8b",
     "locked": false,
     "schema_version": 2,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# Assign your answer to an object called: answer2\n",
    "# Make sure the correct answer is written in lower-case (true / false)\n",
    "# Surround your answer with quotation marks.\n",
    "# Replace the fail() with your answer. \n",
    "\n",
    "# your code here\n",
    "fail() # No Answer - remove if you provide an answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "fc7f35a473edc7404908ba7a877cb392",
     "grade": true,
     "grade_id": "cell-decda128ce0061b5",
     "locked": true,
     "points": 1,
     "schema_version": 2,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "test_that('Solution is incorrect', {\n",
    "    expect_equal(digest(answer2), '05ca18b596514af73f6880309a21b5dd') # we hid the answer to the test here so you can't see it, but we can still run the test\n",
    "    \n",
    "})\n",
    "print(\"Success!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "3aa65b0e0691453487e08d65bca83e9e",
     "grade": false,
     "grade_id": "cell-b3a3c0bfe11c30aa",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "**Question 1.3** \n",
    "Match the following arguments with the corresponding path that they represent:\n",
    "\n",
    "*Definitions*\n",
    "\n",
    "A. `/Users/my_user/Desktop/UBC/BIOL363/SciaticNerveLab/sn_trial_1.xlsx`\n",
    "\n",
    "B. `https://www.ubc.ca`\n",
    "\n",
    "C. `file_1.csv`\n",
    "\n",
    "D. `/Users/name/Documents/Course_A/homework/my_first_homework.docx`\n",
    "\n",
    "E. `homework/my_second_homework.docx`\n",
    "\n",
    "F. `https://www.random_website.com`\n",
    "\n",
    "\n",
    "*Functions*\n",
    "\n",
    "1. absolute\n",
    "2. relative\n",
    "3. URL\n",
    "\n",
    "For every argument, create an object using the letter associated with the example and assign it to the corresponding number from the list of path types. For example: `B <- 1`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c49b5f4a214e4529badb6e97910469d8",
     "grade": false,
     "grade_id": "cell-09da6197edcf6859",
     "locked": false,
     "schema_version": 2,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# Assign your answer to a letter: A, B, C, D, E, F\n",
    "# Make sure the correct answer is a numerical number from 1-6 \n",
    "# Replace the fail() with your answer. \n",
    "\n",
    "# your code here\n",
    "fail() # No Answer - remove if you provide an answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "371b37e742d0fa0390df0e0735c543b0",
     "grade": true,
     "grade_id": "cell-bcb67971fe82e848",
     "locked": true,
     "points": 3,
     "schema_version": 2,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "test_that('Solution is incorrect', {\n",
    "    expect_equal(digest(A), '6717f2823d3202449301145073ab8719') # we hid the answer to the test here so you can't see it, but we can still run the test\n",
    "    expect_equal(digest(B), 'e5b57f323c7b3719bbaaf9f96b260d39') # we hid the answer to the test here so you can't see it, but we can still run the test\n",
    "    expect_equal(digest(C), 'db8e490a925a60e62212cefc7674ca02') # we hid the answer to the test here so you can't see it, but we can still run the test\n",
    "    expect_equal(digest(D), '6717f2823d3202449301145073ab8719') # we hid the answer to the test here so you can't see it, but we can still run the test\n",
    "    expect_equal(digest(E), 'db8e490a925a60e62212cefc7674ca02') # we hid the answer to the test here so you can't see it, but we can still run the test\n",
    "    expect_equal(digest(F), 'e5b57f323c7b3719bbaaf9f96b260d39') # we hid the answer to the test here so you can't see it, but we can still run the test\n",
    "    \n",
    "})\n",
    "print(\"Success!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "bba1109f56a5c788e090c35311b059e1",
     "grade": false,
     "grade_id": "cell-4589f01853a62fe7",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "**Question 1.4**\n",
    "\n",
    "If the absolute path to a data file looks like this: `/Users/my_user/Desktop/UBC/BIOL363/SciaticNerveLab/sn_trial_1.xlsx`\n",
    "\n",
    "What would the relative path look like if the working directory (i.e., where the Jupyter notebook is where you are running your R code from) is now located in the `UBC` folder?\n",
    "\n",
    "A. `read_csv(\"sn_trial_1.xlsx\")`\n",
    "\n",
    "B. `read_csv(\"/SciaticNerveLab/sn_trial_1.xlsx\")`\n",
    "\n",
    "C. `read_csv(\"BIOL363/SciaticNerveLab/sn_trial_1.xlsx\")`\n",
    "\n",
    "D. `read_csv(\"UBC/BIOL363/SciaticNerveLab/sn_trial_1.xlsx\")`\n",
    "\n",
    "E. `read_csv(\"/BIOL363/SciaticNerveLab/sn_trial_1.xlsx\")`\n",
    "\n",
    "*Assign your answer to an object called `answer4`.* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "725524c96241da5d407699e9af6e91a6",
     "grade": false,
     "grade_id": "cell-c7993ed9e8e63184",
     "locked": false,
     "schema_version": 2,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# Assign your answer to an object called: answer4\n",
    "# Make sure the correct answer is an uppercase letter. \n",
    "# Surround your answer with quotation marks.\n",
    "# Replace the fail() with your answer. \n",
    "\n",
    "# your code here\n",
    "fail() # No Answer - remove if you provide an answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "00cda461d02791187935ae75f254adbe",
     "grade": true,
     "grade_id": "cell-0a781125473dc3d8",
     "locked": true,
     "points": 1,
     "schema_version": 2,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "test_that('Solution is incorrect', {\n",
    "    expect_equal(digest(answer4), '475bf9280aab63a82af60791302736f6') # we hid the answer to the test here so you can't see it, but we can still run the test\n",
    "    \n",
    "})\n",
    "print(\"Success!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Argument Modifications to Read Data\n",
    "Reading files is one of the first steps to wrangling data and consequently `read_csv` is a  crucial function. However, despite how effortlessly it has worked so far, it has its limitations. `read_csv` works with particular files and does not accept differing formats. \n",
    "\n",
    "Not all data sets come as perfectly organized like the ones you worked with last week. Time and effort was put into ensuring that the files were arranged with headers, columns were separated by commas, and the beginning excluded metadata. \n",
    "\n",
    "Now that you understand how to read files located outside (or inside) of your working directory, you can begin to learn the tips and tricks necessary to overcoming the setbacks of `read_csv`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Run this cell to learn more about the arguments used in read_csv\n",
    "### Reading over the help file will assist with the next question. \n",
    "\n",
    "?read_csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "dd146847b828c6d772f4d5700c5467f0",
     "grade": false,
     "grade_id": "cell-d827ca1d36fb14e0",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "**Question 2.1** \n",
    "\n",
    "Match the following definitions with the corresponding arguments used in `read_csv`:\n",
    "\n",
    "*Definitions*\n",
    "\n",
    "G. Character that separates columns in your file. \n",
    "\n",
    "H. Specifies whether or not the first row of data in your file are column labels. Also allows you to create a vector that can be used to label columns. \n",
    "\n",
    "I. This is the file name, path to a file, or URL. \n",
    "\n",
    "J. Specifies the number of lines which must be ignored because they contain metadata. \n",
    "\n",
    "\n",
    "*Functions*\n",
    "\n",
    "1. `file`\n",
    "2. `delim`\n",
    "3. `col_names`\n",
    "4. `skip`\n",
    "\n",
    "For every description, create an object using the letter associated with the definition and assign it to the corresponding number from the list of functions. For example: `G <- 1`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6574e61d97f82c4011934853baf53c1d",
     "grade": false,
     "grade_id": "cell-bbc885297c410cb2",
     "locked": false,
     "schema_version": 2,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# Assign your answer to a letter: G, H, I, J\n",
    "# Make sure the correct answer is a numerical number from 1-4\n",
    "# Replace the fail() with your answer. \n",
    "\n",
    "# your code here\n",
    "fail() # No Answer - remove if you provide an answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "75a6bf1afb4e354b1f12ccfb46f62197",
     "grade": true,
     "grade_id": "cell-50ce2f054a8c009a",
     "locked": true,
     "points": 2,
     "schema_version": 2,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "test_that('Solution is incorrect', {\n",
    "    expect_equal(digest(G), 'db8e490a925a60e62212cefc7674ca02') # we hid the answer to the test here so you can't see it, but we can still run the test\n",
    "    expect_equal(digest(H), 'e5b57f323c7b3719bbaaf9f96b260d39') # we hid the answer to the test here so you can't see it, but we can still run the test\n",
    "    expect_equal(digest(I), '6717f2823d3202449301145073ab8719') # we hid the answer to the test here so you can't see it, but we can still run the test\n",
    "    expect_equal(digest(J), 'dbc09cba9fe2583fb01d63c70e1555a8') # we hid the answer to the test here so you can't see it, but we can still run the test\n",
    "    \n",
    "})\n",
    "print(\"Success!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "45dcdedd206760789785f751959f881e",
     "grade": false,
     "grade_id": "cell-5b3f94746c785534",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "**Question 2.2** True or False:\n",
    "\n",
    "`read_csv2` and `read_delim` can both be used for reading files that have columns separated by `;`. \n",
    "\n",
    "*Assign your answer to an object called `answer2.2`. Make sure to write in all lower-case.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7a9bc4871f18d591817d9a93e5029157",
     "grade": false,
     "grade_id": "cell-a35b96936f6bb761",
     "locked": false,
     "schema_version": 2,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# Assign your answer to an object called: answer2.2\n",
    "# Make sure the correct answer is written in lower-case (true / false)\n",
    "# Surround your answer with quotation marks.\n",
    "# Replace the fail() with your answer. \n",
    "\n",
    "# your code here\n",
    "fail() # No Answer - remove if you provide an answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7f39eba40c88fe117016f535fc91b7ff",
     "grade": true,
     "grade_id": "cell-7e29230345864f5d",
     "locked": true,
     "points": 1,
     "schema_version": 2,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "test_that('Solution is incorrect', {\n",
    "    expect_equal(digest(answer2.2), '05ca18b596514af73f6880309a21b5dd') # we hid the answer to the test here so you can't see it, but we can still run the test\n",
    "    \n",
    "})\n",
    "print(\"Success!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "9cf0aaf55afdf595144c59f2a0edf0d1",
     "grade": false,
     "grade_id": "cell-4750064840f67738",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "**Question 2.3** Multiple Choice: \n",
    "\n",
    "`read_tsv` would be used for files that have columns separated by which of the following:\n",
    "\n",
    "A. letters\n",
    "\n",
    "B. tabs\n",
    "\n",
    "C. numbers\n",
    "\n",
    "D. commas \n",
    "\n",
    "*Assign your answer to an object called `answer2.3`.* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "af684aee047e1b5d575da9514658974f",
     "grade": false,
     "grade_id": "cell-518590cd5df1f1b7",
     "locked": false,
     "schema_version": 2,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# Assign your answer to an object called: answer2.3\n",
    "# Make sure the correct answer is an uppercase letter. \n",
    "# Surround your answer with quotation marks.\n",
    "# Replace the fail() with your answer. \n",
    "\n",
    "# your code here\n",
    "fail() # No Answer - remove if you provide an answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5cfebc3031cd629bf40ca9babcbb6114",
     "grade": true,
     "grade_id": "cell-8dfe160165696251",
     "locked": true,
     "points": 1,
     "schema_version": 2,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "test_that('Solution is incorrect', {\n",
    "    expect_that(exists('answer2.3'), is_true())\n",
    "    expect_equal(digest(answer2.3), '3a5505c06543876fe45598b5e5e5195d') # we hid the answer to the test here so you can't see it, but we can still run the test\n",
    "    \n",
    "})\n",
    "print(\"Success!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e394898851ed7dfe19ef0d103ee5b591",
     "grade": false,
     "grade_id": "cell-ba92ca46de3933fe",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "## 3. Happiness Report (2017)\n",
    "This data was taken from [Kaggle](https://www.kaggle.com/unsdsn/world-happiness/home) and ranks countries on happiness based on rationalized factors like economic growth, social support, etc. The data was released by the United Nations at an event celebrating International Day of Happiness. According to the website, the file contains the following information:\n",
    "\n",
    "* Country = Name of the country.\n",
    "* Region = Region the country belongs to.\n",
    "* Happiness Rank = Rank of the country based on the Happiness Score.\n",
    "* Happiness Score = A metric measured by asking the sampled people the question: \"How would you rate your happiness on a scale of 0 to 10 where 10 is the happiest.\"\n",
    "* Standard Error = The standard error of the happiness score.\n",
    "* Economy (GDP per Capita) = The extent to which GDP contributes to the calculation of the Happiness Score.\n",
    "* Family = The extent to which Family contributes to the calculation of the Happiness Score.\n",
    "* Health (Life Expectancy) = The extent to which Life expectancy contributed to the calculation of the Happiness Score.\n",
    "* Freedom = The extent to which Freedom contributed to the calculation of the Happiness Score.\n",
    "* Trust (Government Corruption) = The extent to which Perception of Corruption contributes to Happiness Score.\n",
    "* Generosity = The extent to which Generosity contributed to the calculation of the Happiness Score.\n",
    "* Dystopia Residual = The extent to which Dystopia Residual contributed to the calculation of the Happiness Score.\n",
    "\n",
    "To clean up the file and make it easier to read, we only kept the country name, happiness score, economy (GDP per capita), life expectancy, and freedom.\n",
    "\n",
    "Kaggle stores this information but it is compiled by the *Sustainable Development Solutions Network*. They survey these factors nearly every year (since 2012) and allow global comparisons to optimize political decision making. These landmark surveys are highly recognized and allow countries to learn and grow from one another. One day, they will provide a historical insight on the nature of our time.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "6300ca49b853ff4de8db105eee560031",
     "grade": false,
     "grade_id": "cell-4f9336c659cb50f6",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "**Question 3.1** Fill in the Blank: \n",
    "\n",
    "Trust is the extent to which _______________ contributes to the Happiness Score. \n",
    "\n",
    "A. Corruption \n",
    "\n",
    "B. Government Intervention \n",
    "\n",
    "C. Perception of Corruption  \n",
    "\n",
    "D. Tax Money Designation \n",
    "\n",
    "*Assign your answer to an object called `answer3.1`.* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e7a34ea56033ce4bb7e8542fea07bf7d",
     "grade": false,
     "grade_id": "cell-b4e3e33488ef32b7",
     "locked": false,
     "schema_version": 2,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# Assign your answer to an object called: answer3.1\n",
    "# Make sure the correct answer is an uppercase letter. \n",
    "# Surround your answer with quotation marks.\n",
    "# Replace the fail() with your answer. \n",
    "\n",
    "# your code here\n",
    "fail() # No Answer - remove if you provide an answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "54d150f4649c3069fec01851a552132f",
     "grade": true,
     "grade_id": "cell-56c422da7266129b",
     "locked": true,
     "points": 1,
     "schema_version": 2,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "test_that('Solution is incorrect', {\n",
    "    expect_equal(digest(answer3.1), '475bf9280aab63a82af60791302736f6') # we hid the answer to the test here so you can't see it, but we can still run the test\n",
    "    \n",
    "})\n",
    "print(\"Success!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "3145a6bce9d160b02ec34dac7047ecc2",
     "grade": false,
     "grade_id": "cell-783457361cf6c5df",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "**Question 3.2** Multiple Choice: \n",
    "\n",
    "What is the happiness report?\n",
    "\n",
    "A. Study conducted by the governments of multiple countries. \n",
    "\n",
    "B. Independent survey that was sampled by citizens. \n",
    "\n",
    "C. Study conducted by the UN. \n",
    "\n",
    "D. Survey given to international students by UBC's psychology department. \n",
    "\n",
    "*Assign your answer to an object called `answer3.2`.* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a4ed4944be1637faa30be707becf4960",
     "grade": false,
     "grade_id": "cell-f11d6a9fb2cb9712",
     "locked": false,
     "schema_version": 2,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# Assign your answer to an object called: answer3.1\n",
    "# Make sure the correct answer is an uppercase letter. \n",
    "# Surround your answer with quotation marks.\n",
    "# Replace the fail() with your answer. \n",
    "\n",
    "# your code here\n",
    "fail() # No Answer - remove if you provide an answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b42b71516a39983de3081040950e0f1f",
     "grade": true,
     "grade_id": "cell-7566d4f3f306ca1c",
     "locked": true,
     "points": 1,
     "schema_version": 2,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "test_that('Solution is incorrect', {\n",
    "    expect_equal(digest(answer3.2), '3a5505c06543876fe45598b5e5e5195d') # we hid the answer to the test here so you can't see it, but we can still run the test\n",
    "    \n",
    "})\n",
    "print(\"Success!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7d6b09ec7ec230310514c796a6d4d0a9",
     "grade": false,
     "grade_id": "cell-d034da5aced69138",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "**Question 3.3** Read the file \"happiness_report.csv\" using the shortest relative path. *hint - preview the data using Jupyter (as shown in [this video](https://www.youtube.com/watch?v=6orO4YMAyeQ)) so you know which `read_*` function and which arguments to use).\n",
    "\n",
    "Note, this file is found in the same folder as the worksheet you are completing. \n",
    "\n",
    "*Assign your answer to an object called `happiness_report`.* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "daa443114dcecfb1978ca9b322537ece",
     "grade": false,
     "grade_id": "cell-9637860c62acbf70",
     "locked": false,
     "schema_version": 2,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# Load happiness_report.csv using read_csv and name it: happiness_report\n",
    "\n",
    "# your code here\n",
    "fail() # No Answer - remove if you provide an answer\n",
    "head(happiness_report, n = 10) # the n = 10 argument tells head to print 10 lines instead of the default 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "cc249c3487b24505cccd8b32e93546c7",
     "grade": true,
     "grade_id": "cell-3488c6479abcf3d4",
     "locked": true,
     "points": 1,
     "schema_version": 2,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "test_that('Solution is incorrect', {\n",
    "    expect_equal(digest(ncol(happiness_report)), 'dd4ad37ee474732a009111e3456e7ed7')\n",
    "    expect_equal(digest(nrow(happiness_report)), 'aa46ec0eda6b9268581f7b6334fe5368')\n",
    "    expect_equal(digest(as.numeric(sum(happiness_report$GDP_per_capita))), 'cb8c845eeb80c799ec661eba30abe253') # we hid the answer to the test here so you can't see it, but we can still run the test\n",
    "    \n",
    "})\n",
    "print(\"Success!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "4a2b8055736222df034a4c5da9ece9e4",
     "grade": false,
     "grade_id": "cell-0e8db9c50093cc95",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "**Question 3.4** Multiple Choice:\n",
    "\n",
    "If Norway is in \"first place\" based on the happiness score, at what position is Canada?\n",
    "\n",
    "A. 3rd\n",
    "\n",
    "B. 15th\n",
    "\n",
    "C. 7th\n",
    "\n",
    "D. 28th\n",
    "\n",
    "*Hint: create a new cell and run `happiness_report`.* \n",
    "\n",
    "*Assign your answer to an object called `answer3.4`.* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "01c4917b7664fbc5e4f082130fafc7a8",
     "grade": false,
     "grade_id": "cell-9528400a7684ff70",
     "locked": false,
     "schema_version": 2,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# Assign your answer to an object called: answer3.4\n",
    "# Make sure the correct answer is an uppercase letter. \n",
    "# Surround your answer with quotation marks.\n",
    "# Replace the fail() with your answer. \n",
    "\n",
    "# your code here\n",
    "fail() # No Answer - remove if you provide an answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8e7d11c80ba4c4ed44d710d0f3f108e2",
     "grade": true,
     "grade_id": "cell-3876f08146bbc9ff",
     "locked": true,
     "points": 1,
     "schema_version": 2,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "test_that('Solution is incorrect', {\n",
    "    expect_equal(digest(answer3.4), '475bf9280aab63a82af60791302736f6') # we hid the answer to the test here so you can't see it, but we can still run the test\n",
    "    \n",
    "})\n",
    "print(\"Success!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "4b1e8fdb750ac97b4f353ddaf031e99f",
     "grade": false,
     "grade_id": "cell-9f8a4bdfe511f79b",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "**Question 3.5** \n",
    "\n",
    "Open all the files in the \"data\" folder in your working directory (which should be the `tutorial_01` directory) using Jupyter (again, [this video](https://www.youtube.com/watch?v=6orO4YMAyeQ) shows you how to do this). This will allow you to visualize the files and the organization of your data. Based on your findings, fill in the table below. This table will be very useful to refer back to in the coming weeks. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Double click on this cell to edit and fill out your table!** We have filled the first row as an example.\n",
    "\n",
    "**Fill in your answers between the `|`.**\n",
    "\n",
    "|File Name             | delim | Header (yes/no) | Metadata (yes/no) | # lines to skip | `read_*` function |\n",
    "|----------------------|-------|-----------------|-------------------|-----------------|-------------------|\n",
    "|`happiness_report.csv`|`,`    |yes              |no                 |NA               |`read_csv`         |\n",
    "|                      |       |                 |                   |                 |                   |\n",
    "|                      |       |                 |                   |                 |                   |\n",
    "|                      |       |                 |                   |                 |                   |\n",
    "|                      |       |                 |                   |                 |                   |\n",
    "|                      |       |                 |                   |                 |                   |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "2e6050290d5a91b19b14b3cb55bf0f6a",
     "grade": true,
     "grade_id": "cell-b35ab6be32dd6b35",
     "locked": false,
     "points": 2,
     "schema_version": 2,
     "solution": true
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "712b897e549b2248ef073c0a79adca21",
     "grade": false,
     "grade_id": "cell-ef3eb28b4bd11d8e",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "For the questions below, fill in the `...` in the cells below. Copy and paste your finished answer into the `fail()`. Refer to your table and don't be afraid to ask for help. \n",
    "\n",
    "**Question 3.6.1**\n",
    "\n",
    "Read in the file `happiness_report_semicolon.csv` using `read_delim` and name it `happy_semi_df`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "659b647d6ca1539e54a840e06b91c4af",
     "grade": false,
     "grade_id": "cell-1a59d2fec3747ff0",
     "locked": false,
     "schema_version": 2,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# happy_df <- read_delim(file = \"data/...\", delim = \"...\")\n",
    "\n",
    "# your code here\n",
    "fail() # No Answer - remove if you provide an answer\n",
    "head(happy_semi_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b9fb07e74de763d070b6f5ab103ed582",
     "grade": true,
     "grade_id": "cell-ae36542297ad995b",
     "locked": true,
     "points": 2,
     "schema_version": 2,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "test_that('Solution is incorrect', {\n",
    "    expect_equal(digest(ncol(happy_semi_df)), 'dd4ad37ee474732a009111e3456e7ed7')\n",
    "    expect_equal(digest(nrow(happy_semi_df)), 'aa46ec0eda6b9268581f7b6334fe5368')\n",
    "    expect_equal(digest(sum(happy_semi_df$life_expectancy)), '17c02c6af15ebbf168dbc8a7766166c0') # we hid the answer to the test here so you can't see it, but we can still run the test\n",
    "    \n",
    "})\n",
    "print(\"Success!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "4abd954a2387239e3e8dc3ce9d196ea4",
     "grade": false,
     "grade_id": "cell-2d6d41a3d7f0e440",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "**Question 3.6.2**\n",
    "\n",
    "Read in the file `happiness_report_semicolon.csv` again, but this time use a different `read_*` function than `read_delim` (but that also works). Name it `happy_semi_df2`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1d5fcba41008a93e5c8f4890cce02fd1",
     "grade": false,
     "grade_id": "cell-dfa890bab0fa0ec8",
     "locked": false,
     "schema_version": 2,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# happy_semi_df2 <- ...(\"...\")\n",
    "\n",
    "# your code here\n",
    "fail() # No Answer - remove if you provide an answer\n",
    "head(happy_semi_df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "81d8f3e5f5fdbdd3d768695587f2c372",
     "grade": true,
     "grade_id": "cell-e99b9418831c851b",
     "locked": true,
     "points": 2,
     "schema_version": 2,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "test_that('Solution is incorrect', {\n",
    "    expect_equal(digest(as.numeric(sum(happy_semi_df2$happiness_score))), 'b09ed5fd56dcd21d2a2657ab4142da1f') # we hid the answer to the test here so you can't see it, but we can still run the test\n",
    "    \n",
    "})\n",
    "print(\"Success!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "98db9054d510ee6aa8bde0baf8ed89ba",
     "grade": false,
     "grade_id": "cell-f6fd13c112fece7a",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "**Question 3.6.3**\n",
    "\n",
    "Read in the file `happiness_report.tsv` using the appropriate `read_*` function and name it `happy_tsv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c8de3fd680cdb30467b1288ca28cfef1",
     "grade": false,
     "grade_id": "cell-e25b1333a4928479",
     "locked": false,
     "schema_version": 2,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# happy_tsv <- ...(file = \"...\")\n",
    "\n",
    "# your code here\n",
    "fail() # No Answer - remove if you provide an answer\n",
    "head(happy_tsv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0ddc8e18f9b09689adab60cf3d404231",
     "grade": true,
     "grade_id": "cell-4943aa347e83b909",
     "locked": true,
     "points": 2,
     "schema_version": 2,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "test_that('Solution is incorrect', {\n",
    "    expect_equal(digest(as.numeric(sum(happy_tsv$life_expectancy))), '17c02c6af15ebbf168dbc8a7766166c0') # we hid the answer to the test here so you can't see it, but we can still run the test\n",
    "    \n",
    "})\n",
    "print(\"Success!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "310e5ed446346cb5b420ebed32073cca",
     "grade": false,
     "grade_id": "cell-4bdb6b7ea045900b",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "**Question 3.6.4**\n",
    "\n",
    "Read in the file `happiness_report_metadata.csv` using the appropriate `read_*` function and name it `happy_metadata`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0a2fd9084556e7aae2bf205b38b563d7",
     "grade": false,
     "grade_id": "cell-87cd2b408dab554c",
     "locked": false,
     "schema_version": 2,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# happy_metadata <- ...(\"data/happiness_report_metadata.csv\", skip = ...)\n",
    "\n",
    "# your code here\n",
    "fail() # No Answer - remove if you provide an answer\n",
    "head(happy_metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f3bf5e571268120618cdfc57d096179e",
     "grade": true,
     "grade_id": "cell-e1e499a580fd7227",
     "locked": true,
     "points": 2,
     "schema_version": 2,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "test_that('Solution is incorrect', {\n",
    "    expect_equal(digest(as.numeric(sum(happy_metadata$freedom))), 'd4de4637af7167e9136fe25573414bf6') # we hid the answer to the test here so you can't see it, but we can still run the test\n",
    "    \n",
    "})\n",
    "print(\"Success!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3.6.5**\n",
    "\n",
    "Read in the file `happiness_report_no_header.csv` using the appropriate `read_*` function and name it `happy_header`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "01481cf9f11219e074dcbd7f7d9b7118",
     "grade": false,
     "grade_id": "cell-68d0893af7818c87",
     "locked": false,
     "schema_version": 2,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# happy_header <- ...(\"...\", col_names = c(\"country\", \"happiness_score\", \"GDP_per_capita\", \"life_expectancy\", \"freedom\"))\n",
    "\n",
    "# your code here\n",
    "fail() # No Answer - remove if you provide an answer\n",
    "head(happy_header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b1d65c29f71d6c791f7d35bf7a091160",
     "grade": true,
     "grade_id": "cell-abb25e9b6b619bf1",
     "locked": true,
     "points": 2,
     "schema_version": 2,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "test_that('Solution is incorrect', {\n",
    "    expect_equal(digest(as.numeric(sum(happy_header$freedom))), 'd4de4637af7167e9136fe25573414bf6') # we hid the answer to the test here so you can't see it, but we can still run the test\n",
    "    \n",
    "})\n",
    "print(\"Success!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "9d6fd0e5a6b737b8f20a46433b90f8a7",
     "grade": false,
     "grade_id": "cell-9ef61e2af378b40d",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "**Question 3.7** \n",
    "\n",
    "Opening the data on a text editor showed some clear differences. Do all the data sets look the same once reading them on your R notebook? \n",
    "\n",
    "`yes`\n",
    "`no`\n",
    " \n",
    "*Assign your answer to an object called `answer3.7`. Make sure to write in all lower-case.* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "dfa3fccaabf2339ee2ff095a2c14370a",
     "grade": false,
     "grade_id": "cell-ca10e96ab5e42077",
     "locked": false,
     "schema_version": 2,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# Assign your answer to an object called: answer3.7\n",
    "# Make sure the correct answer is written in lower-case (yes / no)\n",
    "# Surround your answer with quotation marks.\n",
    "# Replace the fail() with your answer. \n",
    "\n",
    "# your code here\n",
    "fail() # No Answer - remove if you provide an answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3c2396add76b7bb60899c35291f02560",
     "grade": true,
     "grade_id": "cell-b10f0e14c91d5ebf",
     "locked": true,
     "points": 1,
     "schema_version": 2,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "test_that('Solution is incorrect', {\n",
    "    expect_equal(digest(answer3.7), '0590b0427c1b19a6eb612d19888aa52f') # we hid the answer to the test here so you can't see it, but we can still run the test\n",
    "    \n",
    "})\n",
    "print(\"Success!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "fc9209fa4335e97def5ae4409b657639",
     "grade": false,
     "grade_id": "cell-e8cd9683896b730d",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "**Question 3.8** \n",
    "\n",
    "Using the `happy_header` data set that you read earlier, plot `GDP_per_capita` vs. `life_expectancy`. \n",
    "\n",
    "*Assign your answer to an object called `header_plot`.* \n",
    "Make sure to use xlab and ylab to label your axes appropriately. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "66e11c4a50673616dfbac6d92424365f",
     "grade": false,
     "grade_id": "cell-1341c1e60d1df98d",
     "locked": false,
     "schema_version": 2,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "options(repr.plot.width=4, repr.plot.height=3)\n",
    "# Assign your plot to an object called: header_plot\n",
    "\n",
    "# your code here\n",
    "fail() # No Answer - remove if you provide an answer\n",
    "header_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "41b8713353e6d0b37d06c996ec417c57",
     "grade": true,
     "grade_id": "cell-06afbc4c37639e7d",
     "locked": true,
     "points": 2,
     "schema_version": 2,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "test_that('GDP_per_capita should be on the x-axis', {\n",
    "    expect_that(\"GDP_per_capita\" %in% c(rlang::get_expr(header_plot$mapping$x), rlang::get_expr(header_plot$layers[[1]]$mapping$x)) , is_true())\n",
    "    })\n",
    "test_that('life_expectancy should be on the y-axis', {\n",
    "    expect_that(\"life_expectancy\" %in% c(rlang::get_expr(header_plot$mapping$y), rlang::get_expr(header_plot$layers[[1]]$mapping$y)) , is_true())\n",
    "    })\n",
    "test_that('geom should be geom_point', {\n",
    "    expect_that(\"GeomPoint\" %in% c(class(header_plot$layers[[1]]$geom)) , is_true())\n",
    "    })\n",
    "print(\"Success!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Reading Data from the Internet\n",
    "\n",
    "### How has the World Gross Domestic product changed throughout history?\n",
    "\n",
    "\n",
    "As defined on Wikipedia, the \"Gross world product (GWP) is the combined gross national product of all the countries in the world.\" Living in our modern age with our roaring (sometimes up and sometimes down) economies, one might wonder how the world economy has changed over history. To answer this question we will scrape data from the [Wikipedia Gross world product page](https://en.wikipedia.org/wiki/Gross_world_product).\n",
    "\n",
    "Your data set will include the following columns: \n",
    "* `year`\n",
    "* `gwp_value`\n",
    "\n",
    "Specifically we will scrape the 2 columns named \"Year\" and \"Real GWP\" in the table under the header \"Historical and prehistorical estimates\". **The end goal of this exercise is to create a line plot with year on the x-axis and GWP value on the y-axis.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "029a0804133a356a3728400de5b54bf7",
     "grade": false,
     "grade_id": "cell-2cfe0d273d96fdf7",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "**Question 4.1.0** Multiple Choice: \n",
    "\n",
    "Under which of the following headers is the table will we scrape from on the [Wikipedia Gross world product page](https://en.wikipedia.org/wiki/Gross_world_product)?\n",
    "\n",
    "A. Gross world product\n",
    "\n",
    "B. Recent growth\n",
    "\n",
    "C. Historical and prehistorical estimates\n",
    "\n",
    "D. See also\n",
    "\n",
    "*Assign your answer to an object called `answer4.1.0`.* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0085db491c0c4d2031ec65e80f52aacd",
     "grade": false,
     "grade_id": "cell-a9b7dd149eeb7782",
     "locked": false,
     "schema_version": 2,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# Assign your answer to an object called: answer4.1.0\n",
    "# Make sure the correct answer is an uppercase letter. \n",
    "# Surround your answer with quotation marks.\n",
    "# Replace the fail() with your answer. \n",
    "\n",
    "# your code here\n",
    "fail() # No Answer - remove if you provide an answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c03e4669452e42659753071f35357a19",
     "grade": true,
     "grade_id": "cell-631492053b2d5ec4",
     "locked": true,
     "points": 1,
     "schema_version": 2,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "test_that('Solution is incorrect', {\n",
    "    expect_equal(digest(as.character(answer4.1.0)), '475bf9280aab63a82af60791302736f6') # we hid the answer to the test here so you can't see it, but we can still run the test\n",
    "    \n",
    "})\n",
    "print(\"Success!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "8ce5b695b865b80a1fc9622a916e391b",
     "grade": false,
     "grade_id": "cell-cc8eaf2a5c4886c3",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "**Question 4.1.1** Multiple Choice: \n",
    "\n",
    "What is going to be the x-axis of the scatter plot we create?\n",
    "\n",
    "A. compound annual growth rate\n",
    "\n",
    "B. the value of the gross world product\n",
    "\n",
    "C. year\n",
    "\n",
    "*Assign your answer to an object called `answer4.1.1`.* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "65964cf830b373bc0494409f42b4d0a8",
     "grade": false,
     "grade_id": "cell-6a1ec0727ab3608a",
     "locked": false,
     "schema_version": 2,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# Assign your answer to an object called: answer4.1.1\n",
    "# Make sure the correct answer is an uppercase letter. \n",
    "# Surround your answer with quotation marks.\n",
    "# Replace the fail() with your answer. \n",
    "\n",
    "# your code here\n",
    "fail() # No Answer - remove if you provide an answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ab847a1d48d78dd858d106713245b94b",
     "grade": true,
     "grade_id": "cell-29f38784d22f2c8b",
     "locked": true,
     "points": 1,
     "schema_version": 2,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "test_that('Solution is incorrect', {\n",
    "    expect_equal(digest(as.character(answer4.1.1)), '475bf9280aab63a82af60791302736f6') # we hid the answer to the test here so you can't see it, but we can still run the test\n",
    "    \n",
    "})\n",
    "print(\"Success!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to now load the `rvest` package to begin our web scraping!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell \n",
    "library(rvest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e6c0aa77eecd02feef48d99019c6b6db",
     "grade": false,
     "grade_id": "cell-5815e9c54d669efe",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "**Question 4.2**\n",
    "\n",
    "Use `read_html` to download information from the URL given in the cell below. \n",
    "\n",
    "*Assign your answer to an object called `golden_globes`.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "da308fe6a1dbd7a428c43e270834cc85",
     "grade": false,
     "grade_id": "cell-eb85da73cb3eedb1",
     "locked": false,
     "schema_version": 2,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# Assign your answer to an object called: gwp\n",
    "# Instead of copying the entire URL, you can simply use the object (url) after read_html()\n",
    "\n",
    "url <- 'https://en.wikipedia.org/wiki/Gross_world_product'\n",
    "\n",
    "# your code here\n",
    "fail() # No Answer - remove if you provide an answer\n",
    "print(gwp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3a45f6caa6dc913bc0608e3cfd1910ec",
     "grade": true,
     "grade_id": "cell-0c1e5c213d4da058",
     "locked": true,
     "points": 2,
     "schema_version": 2,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "test_that('Solution is incorrect', {\n",
    "    expect_that(is.list(gwp), is_true())\n",
    "    expect_equal(digest(as.numeric(length(gwp))), 'db8e490a925a60e62212cefc7674ca02') # we hid the answer to the test here so you can't see it, but we can still run the test\n",
    "    expect_that('xml_document' %in% attributes(gwp)$class, is_true())\n",
    "})\n",
    "print(\"Success!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c90fb571b70f0740ec5418a403363f0f",
     "grade": false,
     "grade_id": "cell-f3a7fe22bb441577",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "**Question 4.3.0**\n",
    "\n",
    "Run the cell below to create the first column of your data set (the year from the table under the \"Historical and prehistorical estimates\" header). The node was obtained using `SelectorGadget`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ef10cd5560270e964ec5f11734edcef8",
     "grade": false,
     "grade_id": "cell-9e4b6854390a4609",
     "locked": false,
     "schema_version": 2,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# Run this cell to create the first column for your data set. \n",
    "# your code here\n",
    "fail() # No Answer - remove if you provide an answer\n",
    "year <- gwp %>%\n",
    "    html_nodes(\".wikitable tbody:nth-child(1) td:nth-child(1)\") %>%\n",
    "    html_text() \n",
    "head(year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d816081fd1f3e5bb290517762463093a",
     "grade": true,
     "grade_id": "cell-d108687ccd76da5e",
     "locked": true,
     "points": 1,
     "schema_version": 2,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "test_that('Solution is incorrect', {\n",
    "    expect_equal(digest(as.character(head(year))), '60024ffc973833818fa99549a0a5ee93') # we hid the answer to the test here so you can't see it, but we can still run the test\n",
    "    \n",
    "})\n",
    "print(\"Success!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that although we want numbers for the year, the data we scraped includes the characters `AD` and `\\n` (a newline character). We will have to do some string manipulation and then convert the years from characters to numbers. \n",
    "\n",
    "First we use the `str_replace_all` function to match the string `\" AD\\n\"` and replace it with nothing `\"\"`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run this cell\n",
    "# use stringr library\n",
    "library(stringr)\n",
    "# replace \" AD\\n\" with nothing\n",
    "year <- str_replace_all(string = year, pattern = \" AD\\n\", replacement = \"\")\n",
    "\n",
    "print(year)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we print year, we can see we were able to remove `\" AD\\n\"`, but we missed that there is also `\" BC\\n\"` on the earliest years! There are also commas (`\",\"`) in the large BC years that we will have to remove. We also need to put a `-` sign in front of the BC numbers so we don't confuse them with the AD numbers after we convert everything to numbers. To do this we will need to use a similar strategy to clean this all up! \n",
    "\n",
    "This week we will provide you the code to do this cleaning, next week you will learn to do these kinds of things yourself. After we do all the string/text manipulation then we use the `as.numeric` function to convert the text to numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run this cell to clean up the year data and convert it to a number\n",
    "# use grep to select the lines containing \" BC\\n\" and put a - at the beginning of them\n",
    "year[grepl(pattern = \" BC\\n\", x = year)] <- str_replace_all(string = year[grepl(pattern = \" BC\\n\", x = year)], pattern = \"^\", replacement = \"-\")\n",
    "\n",
    "# replace all commas with nothing\n",
    "year <- str_replace_all(string = year, pattern = \",\", replacement = \"\")\n",
    "# extract the minus symbol and the numbers\n",
    "year <- str_extract(string = year, pattern = \"-?[0-9]+\") %>% \n",
    "    as.numeric()\n",
    "\n",
    "print(year)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "824670885c8a25c8ec271d8836e170d3",
     "grade": false,
     "grade_id": "cell-ee11d70af0ae1f21",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "**Question 4.4**\n",
    "\n",
    "Create a new column for the gross world product (GWP) from the table we are scraping. Don't forget to use `SelectorGadget` to obtain the CSS selector needed to scrape the GWP values from the table we are scraping. Assign your answer to an object called `gwp_value`. \n",
    "\n",
    "Fill in the `...` in the cell below. Copy and paste your finished answer into the `fail()`. \n",
    "\n",
    "Refer to **Question 4.3** and don't be afraid to ask for help. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b210d19ce2ad08342474e451bf5267cd",
     "grade": false,
     "grade_id": "cell-705feac11fb8dd13",
     "locked": false,
     "schema_version": 2,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# gwp_value <- gwp %>%\n",
    "  # ...(\"...\") %>%\n",
    "  # html_text() \n",
    "\n",
    "# your code here\n",
    "fail() # No Answer - remove if you provide an answer\n",
    "head(gwp_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8a7b8d4c363d95b031f85d8cf9630d74",
     "grade": true,
     "grade_id": "cell-15126d99f838d9b6",
     "locked": true,
     "points": 2,
     "schema_version": 2,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "test_that('Solution is incorrect', {\n",
    "    expect_that(is.vector(gwp_value), is_true())\n",
    "    expect_equal(digest(as.character(head(gwp_value))), '8aea984d028a6cb86143f8bd9c961a26') # we hid the answer to the test here so you can't see it, but we can still run the test\n",
    "    \n",
    "})\n",
    "print(\"Success!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, looking at the output of `head(gwp_value)` we see we have some cleaning and type conversions to do. We need to remove the commas, the extraneous trailing information in the first 3 columns, and the `\"\\n\"` character again. We provide the code to do this below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run this cell to clean up the year data and convert it to a number\n",
    "# create a new variable called gwp_value_clean\n",
    "gwp_value_clean <-  gwp_value\n",
    "# replace all commas with nothing\n",
    "gwp_value <- str_replace_all(string = gwp_value, pattern = \",\", replacement = \"\")\n",
    "# extract the numbers and decimals\n",
    "gwp_value <- str_extract(string = gwp_value, pattern = \"[0-9.]+\") %>% \n",
    "    as.numeric()\n",
    "print(gwp_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b0061fd6a1e9130f6f06c83da79586ae",
     "grade": false,
     "grade_id": "cell-e7cd941c74d291b3",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "**Question 4.5**\n",
    "\n",
    "Use the `tidyverse` tibble function to create a data frame named `gwp` with `year` and `gwp_value` as columns. The general form for the creating data frames from vectors/lists using the `tibble` function is as follows:\n",
    "\n",
    "```tibble(COLUMN1_NAME, COLUMN2_NAME, COLUMN3_NAME, ...)```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "70ae00416e2e86f4b70be14835b7ff81",
     "grade": false,
     "grade_id": "cell-d1371cd4b958c5bc",
     "locked": false,
     "schema_version": 2,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# create data.frame with columns year and gwp_value named gwp\n",
    "# fill in the blanks in the code skeleton provided below\n",
    "#... <- tibble(..., ...)\n",
    "\n",
    "# your code here\n",
    "fail() # No Answer - remove if you provide an answer\n",
    "head(gwp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a4f4dabbb41f61eb29f3ed12e6a1a641",
     "grade": true,
     "grade_id": "cell-2e58f17d6d715a58",
     "locked": true,
     "points": 1,
     "schema_version": 2,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "test_that('Solution is incorrect', {\n",
    "    expect_equal(digest(as.numeric(sum(gwp$year))), 'a531a2d37eb64bf5b3ffb7ee17dbaedc')\n",
    "    expect_equal(digest(as.numeric(sum(gwp$gwp_value))), 'f555139e88b37cd50d8c5d170ea575bd')\n",
    "})\n",
    "print(\"Success!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One last piece of data transformation/wrangling we will do before we get to data visualization is to create another column called `sqrt_year` which scales the year values so that they will be more informative when we plot them (if you look at our year data we have a lot of years in the recent past, and fewer and fewer as we go back in time). Often times you can just transform the scale within `ggplot` (for example see what we do with the `gwp_value` later on), but the year value is tricky for scaling becuase it contains negative values. So we need to first make everything positive, then take the square root, and then re-transform the values that should be negative to negative again! We provide the code to do this below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gwp <- gwp %>% \n",
    "    mutate(sqrt_year = sqrt(abs(year)))  %>% \n",
    "    mutate(sqrt_year = if_else(year < 0, sqrt_year * -1, sqrt_year))\n",
    "head(gwp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e74d6681c7bfc077198674cfc9f706cb",
     "grade": false,
     "grade_id": "cell-ee318d84dfeeaa45",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "**Question 4.6**\n",
    "\n",
    "Create a line plot using the `gwp` data frame where `sqrt_year` is on the x-axis and `gwp_value` is on the y-axis. *We provide the plot code to relabel the x-axis with the human understandable years instead of the tranformed ones we plot.* Name your plot object `gwp_historical`. To make a line plot instead of a scatter plot you should use the `geom_line()` function instead of the `geom_point()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "751e609c9b650e6c64ba0689a7e20b11",
     "grade": false,
     "grade_id": "cell-bbe05ddba3e2c8e7",
     "locked": false,
     "schema_version": 2,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# Assign your answer to an object called: gwp_historical\n",
    "# Fill in the missing parts of the code below to make the plot\n",
    "\n",
    "#... <- ggplot(gwp, aes(x = ..., y = ...)) +\n",
    "    #geom_line() +\n",
    "    #scale_y_continuous(trans='log10') +\n",
    "    #scale_x_continuous(breaks = c(-1000, -750, -500, -250, -77.7, 0, 38.7), \n",
    "    #                   labels = c(\"-1000000\", \"-562500\", \"-250000\", \"-62500\", \"-5000\", \"0\", \"1500\")) +\n",
    "    #ylab(\"...\") +\n",
    "    #xlab(\"Year\")\n",
    "\n",
    "options(repr.plot.width=8, repr.plot.height=3)\n",
    "# your code here\n",
    "fail() # No Answer - remove if you provide an answer\n",
    "gwp_historical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ec526d1f55afdb53be48ab4c13e26edc",
     "grade": true,
     "grade_id": "cell-bb0696a343e1255c",
     "locked": true,
     "points": 2,
     "schema_version": 2,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "test_that('Solution is incorrect', {\n",
    "    expect_that(\"sqrt_year\" %in% c(rlang::get_expr(gwp_historical$mapping$x), rlang::get_expr(gwp_historical$layers[[1]]$mapping$x)) , is_true())\n",
    "    expect_that(\"gwp_value\" %in% c(rlang::get_expr(gwp_historical$mapping$y), rlang::get_expr(gwp_historical$layers[[1]]$mapping$y)) , is_true())\n",
    "    expect_that(\"GeomLine\" %in% c(class(gwp_historical$layers[[1]]$geom)), is_true())\n",
    "    })\n",
    "print(\"Success!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f431e2bb8f6e66fa1942dda4dce6f461",
     "grade": false,
     "grade_id": "cell-fac12005e571ba5b",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "**Question 4.7** \n",
    "\n",
    "Looking at the line plot, when does the Gross World Dompestic Product first start to more rapidly increase (i.e., when does the slope of the line first change)? \n",
    "\n",
    "A. roughly around year -1,000,000\n",
    "\n",
    "B. roughly around year -250,000\n",
    "\n",
    "C. roughly around year -5000\n",
    "\n",
    "D. roughly around year 1500\n",
    "\n",
    "\n",
    "*Assign your answer to an object called `answer4.7`.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b07d01d2ae7612efcdab00d9a7df10f2",
     "grade": false,
     "grade_id": "cell-dd7f4c508c47aec3",
     "locked": false,
     "schema_version": 2,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# Assign your answer to an object called: answer4.7\n",
    "# Make sure the correct answer is an uppercase letter. \n",
    "# Surround your answer with quotation marks.\n",
    "# Replace the fail() with your answer. \n",
    "\n",
    "# your code here\n",
    "fail() # No Answer - remove if you provide an answer\n",
    "print(answer4.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "47f3b8133f6ee2a04e29fe3381809aeb",
     "grade": true,
     "grade_id": "cell-8375f0716c6f8541",
     "locked": true,
     "points": 1,
     "schema_version": 2,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "test_that('Solution is incorrect', {\n",
    "    expect_equal(digest(as.character(answer4.7)), '475bf9280aab63a82af60791302736f6') # we hid the answer to the test here so you can't see it, but we can still run the test\n",
    "    \n",
    "})\n",
    "print(\"Success!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
